{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Advanced Business Analytics (CIS442D)\n",
    "\n",
    "Python Tool Project (NLTK)\n",
    "\n",
    "Team: Patrick Ward, Simon Krauss, Maulik Dave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b580fe61-93ad-4043-810d-94f519069b1b"
    }
   },
   "source": [
    "# Natural Language Toolkit (nltk):\n",
    "\n",
    "  NLTK is a library with interfaces to work with human language data.  It is a suite of libraries and programs for symbolic and statistical Natural Language Processing(NLP).  This library was developed at the University of Pennsylvania.  It is free, open source prject that is considered \"wonderful tool for teaching, and working in computational linguistics using python.\".   \n",
    "    It is widely used in the computational linguistic, cognitive sciece, machine learning applications.  It supports classification, tokenzation, stemming, tagging, parsing, and sematnic reasoning.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context:\n",
    "\n",
    "Natural Language Processing (NLP) is an area of Computer Science, Artificial Intelligence and Computational Linguistics studying interactions between computers and human (natural) languages.  Main challenge of NLP is natural language understanding -- so computers can understand human or natural language.  \"NLTK\" provides that toolkit for computational semantics and can help us understand language by manipulating written documents. This has practical applications in a variety of fields, from sociologists studying speech patterns in various areas of the world, to business analysts being able to learn more about their customers on social media. Without this library such researchers need to implement functions that NLTK provides e.g. stemming, semantic reasoning, symbolic and statistical natural language processing.  \n",
    "NLTK is also interfaced with annotated corpora (that's what nltk.download() in following section does).  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "71273f19-2320-4752-8528-3c6c4ef4e085"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Installation \n",
    "# NLTK requires Python 2.7 or above versions.\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "150111bf-87f7-4761-a3c6-21f47452f3ac"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIS 442D is very challenging and interesting class !!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['CIS',\n",
       " '442D',\n",
       " 'is',\n",
       " 'very',\n",
       " 'challenging',\n",
       " 'and',\n",
       " 'interesting',\n",
       " 'class',\n",
       " '!',\n",
       " '!']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic examples to show what you can do with NLTK \n",
    "# To make this tutorial accessible to beginners, basic examples are chosen that doesn't require\n",
    "# any prior knowledge of NLP or computational lingustics.\n",
    "\n",
    "sentence = \"\"\"CIS 442D is very challenging and interesting class !!\"\"\"\n",
    "print (sentence)\n",
    "tokens = nltk.word_tokenize(sentence) #interesting !! will be two separate tokens.\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CIS', 'NNP'),\n",
       " ('442D', 'CD'),\n",
       " ('is', 'VBZ'),\n",
       " ('very', 'RB'),\n",
       " ('challenging', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('interesting', 'JJ'),\n",
       " ('class', 'NN'),\n",
       " ('!', '.'),\n",
       " ('!', '.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged = nltk.pos_tag(tokens)\n",
    "tagged[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank\n",
    "t = treebank.parsed_sents('wsj_0001.mrg')[0]\n",
    "t.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('canon powershot g3', '+3'),\n",
       " ('use', '+2'),\n",
       " ('picture', '+2'),\n",
       " ('picture quality', '+1'),\n",
       " ('picture quality', '+1'),\n",
       " ('camera', '+2'),\n",
       " ('use', '+2'),\n",
       " ('feature', '+1'),\n",
       " ('picture quality', '+3'),\n",
       " ('use', '+1'),\n",
       " ('option', '+1')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Annotated customer reviews of products from Amazon\n",
    "# Example illustrates power to analyze user reviews.\n",
    "\n",
    "from nltk.corpus import product_reviews_1\n",
    "camera_reviews = product_reviews_1.reviews('Canon_G3.txt')\n",
    "review = camera_reviews[0]\n",
    "review.features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SentiWordNet\n",
    "# Several corpora with NLTK contain documents that have been categorized for topic, genre, polarity\n",
    "# Example illustrated movie review for sentiments.\n",
    "\n",
    "from nltk.corpus import brown, movie_reviews, reuters\n",
    "movie_reviews.categories()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "These words are removed using the stopwords function:\n",
      " {'to', 'here', 'these', 'up', 'doing', 'yourself', 'needn', 'above', 'how', 'do', 'isn', 'those', 'yourselves', 's', 'nor', 'it', 'will', 'very', 'and', 'because', 't', 'of', 'had', 'while', 'just', 'hers', 'don', 'ours', 'against', 'any', 'mightn', 'itself', 'down', 'his', 'but', 'are', 'he', 'haven', 'won', 'she', 'that', 'aren', 'yours', 'below', 'themselves', 'was', 'an', 'they', 'for', 'having', 'between', 'has', 'll', 'a', 'am', 'other', 'her', 'ourselves', 'being', 'wasn', 'them', 'did', 'through', 'this', 'your', 'at', 'where', 'him', 'when', 'shan', 'm', 'me', 'shouldn', 'once', 'my', 'or', 'so', 're', 'on', 'wouldn', 'weren', 'i', 'too', 'o', 'until', 'what', 'again', 'by', 'before', 'you', 'can', 'herself', 'should', 'their', 'during', 'both', 'hasn', 'then', 'who', 'we', 'as', 'after', 'more', 'if', 'few', 'didn', 'about', 'own', 'under', 'ain', 'our', 'over', 'mustn', 'out', 'not', 'be', 'only', 'its', 'in', 'myself', 'is', 'further', 'y', 'were', 'there', 'whom', 'does', 'all', 'no', 'same', 'than', 'himself', 'some', 'couldn', 'with', 'theirs', 'why', 'off', 'from', 'the', 'into', 'which', 've', 'been', 'now', 'ma', 'such', 'doesn', 'd', 'hadn', 'each', 'most', 'have'}\n",
      "\n",
      "Original sentence:\n",
      " ['This', 'is', 'a', 'filtered', 'sentence']\n",
      "\n",
      "Filtered sentence - the words \"is\", and \"a\" have been filtered out:\n",
      " ['This', 'filtered', 'sentence']\n"
     ]
    }
   ],
   "source": [
    "# Portions of this code were taken from the following source:\n",
    "# https://pythonprogramming.net/stop-words-nltk-tutorial/?completed=/tokenizing-words-sentences-nltk-tutorial/\n",
    "\n",
    "# Link to list of Penn Treebank Project:\n",
    "# https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "    \n",
    "# Using natural language processing, we aim to allow the machine to understand (on a basic level) \n",
    "# what the text means.  The 'stopwords' function allows us to eliminate relatively meaningless words\n",
    "# relative to the message we're trying to convey.\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sentence2 = 'This is a filtered sentence'\n",
    "stop_words = set(stopwords.words('english'))\n",
    "sentence2 = word_tokenize(sentence2)\n",
    "\n",
    "stopwords_sentence = []\n",
    "for i in sentence2:\n",
    "    if i not in stop_words:\n",
    "        stopwords_sentence.append(i)\n",
    "\n",
    "print('\\nThese words are removed using the stopwords function:\\n',set(stopwords.words('english')))\n",
    "print('\\nOriginal sentence:\\n', sentence2)\n",
    "print('\\nFiltered sentence - the words \"is\", and \"a\" have been filtered out:\\n', stopwords_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Features: \n",
    "\n",
    "NLTK has many more advanced features that build on the ideas discussed previously. Some of the more advanced topics include analyzing sentence structure, creating grammars to better understand syntax, and analyzing the meanings of sentences, just to name a few. NLTK can do this using a variety of methods including syntax and parsing trees, which work very similarly to decision trees. Users can also create rules for grammars with a method of ordering words called subsumption. By creating grammars and rules, the program can follow along and actually \"learn\" as the code becomes more complex and begin to understand sentences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "    \n",
    "IBM Watson winning \"Jeopardy\" is a great example of how fast cognitive technology is growing.  AI is becoming mainstream technology service rather than exotic research topic.  With that comes need to understand natural languages/context better by machines.  NLTK library is a solution in that domain as it can be leveraged effectively for learning computational linguistics.  It is free and easy to use.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## References:\n",
    "    \n",
    "(1) www.nltk.org (Official documentation page)\n",
    "\n",
    "(2) https://pythonprogramming.net/stop-words-nltk-tutorial/?completed=/tokenizing-words-sentences-nltk-tutorial/\n",
    "\n",
    "(3) https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "\n",
    "(4) NLTK: The Natural Language Toolkit (Edward Loper and Steven Bird)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbpresent": {
   "slides": {
    "abefdd6f-4489-41f6-83d6-d7f70ad6fcd8": {
     "id": "abefdd6f-4489-41f6-83d6-d7f70ad6fcd8",
     "layout": "grid",
     "prev": null,
     "regions": {
      "00ada303-dcc5-47fc-828d-497d9aec5b75": {
       "attrs": {
        "height": 1,
        "pad": 0.01,
        "treemap:weight": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "id": "00ada303-dcc5-47fc-828d-497d9aec5b75"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
